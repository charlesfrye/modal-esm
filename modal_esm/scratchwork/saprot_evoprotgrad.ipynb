{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evoprotgrad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evo_prot_grad.experts.base_experts import AttributeExpert, Expert\n",
    "from evo_prot_grad import DirectedEvolution\n",
    "from evo_prot_grad.common.tokenizers import ExpertTokenizer, OneHotTokenizer\n",
    "from evo_prot_grad.common.utils import CANONICAL_ALPHABET\n",
    "import evo_prot_grad.common.utils as utils\n",
    "import evo_prot_grad.common.tokenizers as tokenizers\n",
    "from evo_prot_grad.common.embeddings import OneHotEmbedding\n",
    "from typing import List, Tuple, Optional\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaprotOneHotTokenizer(OneHotTokenizer):\n",
    "    \n",
    "    def __init__(self, alphabet: List[str]=CANONICAL_ALPHABET):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alphabet (List[str]): A list of amino acid characters.\n",
    "        \"\"\"\n",
    "        super().__init__(alphabet)\n",
    "    \n",
    "    def remove_structure_tokens(self, seq):\n",
    "        return ''.join([aa[0] for aa in seq if aa[0] in self.alphabet])\n",
    "    \n",
    "    def __call__(self, seqs: List[str]) -> torch.FloatTensor:\n",
    "        # strip structural char\n",
    "        seqs_only = [self.remove_structure_tokens(seq) for seq in seqs]\n",
    "        return super().__call__(seqs=seqs_only)\n",
    "    \n",
    "    def decode(self, ohs: torch.Tensor) -> List[str]:\n",
    "       seqs = super().decode(ohs)\n",
    "       return [self.add_structure_tokens(seq) for seq in seqs]\n",
    "    \n",
    "    def add_structure_tokens(self, seq):\n",
    "        return ''.join([aa + '#' for aa in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaprotRegressionExpert(AttributeExpert):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 temperature: float,\n",
    "                 model: nn.Module,\n",
    "                 scoring_strategy: str,\n",
    "                 device: str,\n",
    "                 tokenizer: Optional[tokenizers.ExpertTokenizer] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            temperature (float): Hyperparameter for re-scaling this expert in the Product of Experts.\n",
    "            model (nn.Module): The model to use for the expert.\n",
    "            scoring_strategy (str): The approach used to score mutations with this expert.\n",
    "            tokenizer (ExpertTokenizer): The tokenizer to use for the expert.\n",
    "            device (str): The device to use for the expert.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(\n",
    "            temperature,\n",
    "            model,\n",
    "            scoring_strategy,\n",
    "            device,\n",
    "            tokenizer=tokenizer\n",
    "            )\n",
    "        self.model.esm.embeddings.word_embeddings = OneHotEmbedding(model.esm.embeddings.word_embeddings)\n",
    "    \n",
    "    def tokenize(self, inputs: List[str]):\n",
    "        \"\"\"Tokenizes a list of protein sequences.\n",
    "        \n",
    "        Args:\n",
    "            inputs (List[str]): A list of protein sequences.\n",
    "        \"\"\"\n",
    "        tokenized = self.tokenizer(inputs, return_tensors=\"pt\", padding=True)\n",
    "        return {k: v.to(self.device) for k, v in tokenized.items()}\n",
    "    \n",
    "    def get_model_output(self, inputs: List[str]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Returns both the onehot-encoded inputs and model's predictions.\n",
    "\n",
    "        Args:\n",
    "            inputs (List[str]): A list of protein sequence strings of len [parallel_chains].\n",
    "        Returns: \n",
    "            x_oh: (torch.Tensor) of shape [parallel_chains, seq_len, vocab_size]\n",
    "            attribute_values: (torch.Tensor) of shape [parallel_chains, seq_len, vocab_size]            \n",
    "        \"\"\"\n",
    "        encoded_inputs = self.tokenize(inputs)\n",
    "        attribute_values = self.model(**encoded_inputs)\n",
    "        oh = self._get_last_one_hots()\n",
    "        return oh, attribute_values\n",
    "    \n",
    "    def _get_last_one_hots(self) -> torch.Tensor:\n",
    "        \"\"\" Returns the one-hot tensors *most recently passed* as input.\n",
    "        \"\"\"\n",
    "        return self.model.esm.embeddings.word_embeddings.one_hots\n",
    "    \n",
    "class SaprotDirectedEvolution(DirectedEvolution):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 experts: List[Expert],\n",
    "                 parallel_chains: int,\n",
    "                 n_steps: int,\n",
    "                 max_mutations: int,\n",
    "                 output: str = 'last',\n",
    "                 preserved_regions: Optional[List[Tuple[int, int]]] = None,\n",
    "                 wt_protein: Optional[str] = None,\n",
    "                 wt_fasta: Optional[str] = None,\n",
    "                 verbose: bool = False,\n",
    "                 random_seed: Optional[int] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            experts (List[Expert]): List of experts\n",
    "            parallel_chains (int): number of parallel chains\n",
    "            n_steps (int): number of steps to run directed evolution\n",
    "            max_mutations (int): maximum mutation distance from WT, disable by setting to -1.\n",
    "            output (str): output type, either 'best', 'last' or 'all'. Default is 'last'.\n",
    "            preserved_regions (List[Tuple[int,int]]): list of tuples of (start, end) of preserved regions. Default is None.\n",
    "            wt_protein (str): wt sequence as a string. Must provide one of wt_protein or wt_fasta.\n",
    "            wt_fasta (str): path to fasta file containing wt sequence.\n",
    "                Must provide one of wt_protein or wt_fasta.\n",
    "            verbose (bool): whether to print verbose output. Default is False.\n",
    "            random_seed (int): random seed for reproducibility. Default is None.\n",
    "        Raises:\n",
    "            ValueError: if `n_steps` < 1.\n",
    "            ValueError: if neither `wt_protein` nor `wt_fasta` is provided.\n",
    "            ValueError: if a fasta file is passed to `wt_protein` argument.\n",
    "            ValueError: if `output` is not one of 'best', 'last' or 'all'.\n",
    "            ValueError: if no experts are provided.\n",
    "            ValueError: if any of the preserved regions are < 1 amino acid long.\n",
    "        \"\"\"\n",
    "        self.experts = experts\n",
    "        self.parallel_chains = parallel_chains\n",
    "        self.n_steps = n_steps\n",
    "        self.max_mutations = max_mutations\n",
    "        self.output = output\n",
    "        self.preserved_regions = preserved_regions\n",
    "        self.wt_protein = wt_protein\n",
    "        self.wt_fasta = wt_fasta\n",
    "        self.verbose = verbose\n",
    "        self.random_seed = random_seed\n",
    "        self.device = self.experts[0].device\n",
    "        \n",
    "        # Checks\n",
    "        if self.n_steps < 1:\n",
    "            raise ValueError(\"`n_steps` must be >= 1\")\n",
    "        if not (self.wt_protein is not None or self.wt_fasta is not None):\n",
    "            raise ValueError(\"Must provide one of `wt_protein` or `wt_fasta`\")\n",
    "        if output not in ['best', 'last', 'all']:\n",
    "            raise ValueError(\"`output` must be one of 'best', 'last' or 'all'\")\n",
    "        if len(self.experts) < 1:\n",
    "            raise ValueError(\"Must provide at least one expert\")\n",
    "        \n",
    "        if random_seed is not None:\n",
    "            utils.set_seed(random_seed)\n",
    "        if self.preserved_regions is not None:\n",
    "            for start, end in self.preserved_regions:\n",
    "                if end - start < 0:\n",
    "                    raise ValueError(\"Preserved regions must be at least 1 amino acid long\")\n",
    "                \n",
    "        # maintains a tokenizer with canonical alphabet\n",
    "        # for the one-hot encoded chains\n",
    "        self.canonical_chain_tokenizer = SaprotOneHotTokenizer()\n",
    "        \n",
    "        if self.wt_protein is not None:\n",
    "            if '.fasta' in self.wt_protein:\n",
    "                raise ValueError(\"Did you mean to use the `wt_fasta` argument instead of `wt_protein`?\")    \n",
    "            self.wtseq = self.wt_protein\n",
    "            # Add spaces between each amino acid if necessary\n",
    "            if ' ' not in self.wtseq:\n",
    "                self.wtseq = ' '.join(self.wtseq)\n",
    "        # Check if wt_protein is a fasta file\n",
    "        elif self.wt_fasta is not None:\n",
    "            self.wtseq = utils.read_fasta(self.wt_fasta)\n",
    "        if self.verbose:\n",
    "            print(f\">Wildtype sequence: {self.wtseq}\")\n",
    "        self.reset()\n",
    "\n",
    "        ### Hyperparams\n",
    "        self.max_pas_path_length = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfp_expert = SaprotRegressionExpert(\n",
    "    temperature=1,\n",
    "    model=models['saprot_yfp'],\n",
    "    tokenizer=models['saprot_tokenizer'],\n",
    "    device='cuda',\n",
    "    scoring_strategy = 'attribute_value',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = top_variants['variant_90']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = ''.join([aa + '#' for aa in s]) + '#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M#V#T#R#L#E#I#H#Y#T#G#E#I#P#V#R#Y#N#L#K#A#D#F#E#G#S#R#Y#T#V#E#G#K#G#T#V#N#P#A#T#G#K#L#T#L#R#L#V#C#T#T#G#D#L#P#V#Y#W#P#T#L#V#T#T#F#G#Y#G#L#Q#C#F#A#E#E#Q#K#G#N#R#I#Y#P#F#M#G#S#W#G#P#R#K#K#V#L#T#R#H#I#T#D#G#K#D#I#V#D#A#T#F#A#F#E#G#N#V#L#V#T#D#V#N#L#Y#A#D#K#G#A#I#N#G#A#I#M#R#K#L#L#K#K#Q#E#R#P#Y#L#H#H#W#R#Y#D#P#E#R#Q#G#F#M#G#A#Q#R#V#F#Q#H#L#K#N#G#K#E#A#E#V#L#E#A#I#E#I#V#K#T#D#N#F#G#H#G#R#P#S#E#Y#V#T#K#Y#T#S#Y#L#G#H#H#A#D#L#L#E#D#A#I#E#I#E#V#A#L#E#Q#F#G#A#D#S#N#G#L#I#A#R#L#G#S#D##'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models['saprot_tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 242, 446])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yfp_expert.get_model_output([sa])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = models['saprot_tokenizer'](sa, return_tensors='pt', add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = {k: v.to('cuda') for k, v in encoded.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.3582]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models['saprot_yfp'](**encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Wildtype sequence: M # V # T # R # L # E # I # H # Y # T # G # E # I # P # V # R # Y # N # L # K # A # D # F # E # G # S # R # Y # T # V # E # G # K # G # T # V # N # P # A # T # G # K # L # T # L # R # L # V # C # T # T # G # D # L # P # V # Y # W # P # T # L # V # T # T # F # G # Y # G # L # Q # C # F # A # E # E # Q # K # G # N # R # I # Y # P # F # M # G # S # W # G # P # R # K # K # V # L # T # R # H # I # T # D # G # K # D # I # V # D # A # T # F # A # F # E # G # N # V # L # V # T # D # V # N # L # Y # A # D # K # G # A # I # N # G # A # I # M # R # K # L # L # K # K # Q # E # R # P # Y # L # H # H # W # R # Y # D # P # E # R # Q # G # F # M # G # A # Q # R # V # F # Q # H # L # K # N # G # K # E # A # E # V # L # E # A # I # E # I # V # K # T # D # N # F # G # H # G # R # P # S # E # Y # V # T # K # Y # T # S # Y # L # G # H # H # A # D # L # L # E # D # A # I # E # I # E # V # A # L # E # Q # F # G # A # D # S # N # G # L # I # A # R # L # G # S # D # #\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m directed_evolution \u001b[38;5;241m=\u001b[39m \u001b[43mSaprotDirectedEvolution\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mwt_protein\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# path to wild type fasta file\u001b[39;49;00m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# return best, last, all variants    \u001b[39;49;00m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mexperts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43myfp_expert\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# list of experts to compose\u001b[39;49;00m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mparallel_chains\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# number of parallel chains to run\u001b[39;49;00m\n",
      "\u001b[1;32m      6\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# number of MCMC steps per chain\u001b[39;49;00m\n",
      "\u001b[1;32m      7\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmax_mutations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# maximum number of mutations per variant\u001b[39;49;00m\n",
      "\u001b[1;32m      8\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# print debug info to command line\u001b[39;49;00m\n",
      "\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[0;32mIn[66], line 104\u001b[0m, in \u001b[0;36mSaprotDirectedEvolution.__init__\u001b[0;34m(self, experts, parallel_chains, n_steps, max_mutations, output, preserved_regions, wt_protein, wt_fasta, verbose, random_seed)\u001b[0m\n",
      "\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>Wildtype sequence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwtseq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m### Hyperparams\u001b[39;00m\n",
      "\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_pas_path_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\n",
      "File \u001b[0;32m~/code/modal-esm/modal-esm/lib/python3.10/site-packages/evo_prot_grad/common/sampler.py:115\u001b[0m, in \u001b[0;36mDirectedEvolution.reset\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchains_oh_history \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m expert \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperts:\n",
      "\u001b[0;32m--> 115\u001b[0m     \u001b[43mexpert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_wildtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwtseq\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/code/modal-esm/modal-esm/lib/python3.10/site-packages/evo_prot_grad/experts/base_experts.py:75\u001b[0m, in \u001b[0;36mExpert.init_wildtype\u001b[0;34m(self, wt_seq)\u001b[0m\n",
      "\u001b[1;32m     68\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set the one-hot encoded wildtype sequence for this expert.\u001b[39;00m\n",
      "\u001b[1;32m     69\u001b[0m \n",
      "\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n",
      "\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    wt_seq (str): The wildtype sequence.\u001b[39;00m\n",
      "\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wt_oh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_output([wt_seq])[\u001b[38;5;241m0\u001b[39m]      \n",
      "\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariant_scoring\u001b[38;5;241m.\u001b[39mcache_wt_score(\n",
      "\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wt_oh, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwt_seq\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;32m     76\u001b[0m )\n",
      "\n",
      "File \u001b[0;32m~/code/modal-esm/modal-esm/lib/python3.10/site-packages/transformers/utils/generic.py:303\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n",
      "\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "directed_evolution = SaprotDirectedEvolution(\n",
    "                   wt_protein = sa,    # path to wild type fasta file\n",
    "                   output = 'all',                # return best, last, all variants    \n",
    "                   experts = [yfp_expert],   # list of experts to compose\n",
    "                   parallel_chains = 1,            # number of parallel chains to run\n",
    "                   n_steps = 20,                   # number of MCMC steps per chain\n",
    "                   max_mutations = 10,             # maximum number of mutations per variant\n",
    "                   verbose = True                  # print debug info to command line\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
